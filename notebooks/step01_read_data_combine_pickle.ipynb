{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team code for loading and pickling data\n",
    "\n",
    "### UPDATED 6/2/2020:\n",
    "- Deleted irrelevant column from 2015 (that had NaN's in almost all fields).\n",
    "- Wanted this done at this stage so that the .pkl file would be clean.\n",
    "- Also updated the \"step02...\" notebook to remove this step.\n",
    "\n",
    "Data source: \n",
    "Physician & Other Supplier Payments   \n",
    "https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Physician-and-Other-Supplier2017  \n",
    "\n",
    "### Reading in 1 dataset\n",
    "- Bringing only specific columns after initial EDA, and lookin at stated business requirements (from HCBB presentation)\n",
    "- Adding year column to each year's df\n",
    "\n",
    "#### Columns to keep\n",
    "National Provider Identifier\n",
    "Last Name/Organization Name of the Provider\n",
    "Entity Type of the Provider\n",
    "City of the Provider\n",
    "Zip Code of the Provider\n",
    "State Code of the Provider\n",
    "Provider Type\n",
    "Place of Service \n",
    "HCPCS Code\n",
    "HCPCS Description\n",
    "Number of Services \n",
    "Number of Medicare Beneficiaries \n",
    "Number of Distinct Medicare Beneficiary/Per Day Services \n",
    "Average Medicare Allowed Amount \n",
    "ADD: Year (in each df on import)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tried importing via chunking and that took longer than NOT chunking. See bottom of notebook for code used for chunking experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# This step loads in only the columns we want, \n",
    "# adds a column for year, and \n",
    "# converts column headers to have no spaces or special characters\n",
    "# This is for 2017. Years 2016 and 2015 are below.\n",
    "\n",
    "cols = ['National Provider Identifier',\n",
    "        'Last Name/Organization Name of the Provider',\n",
    "        'Entity Type of the Provider',\n",
    "        'City of the Provider',\n",
    "        'Zip Code of the Provider',\n",
    "        'State Code of the Provider',\n",
    "        'Provider Type',\n",
    "        'Place of Service',\n",
    "        'HCPCS Code',\n",
    "        'HCPCS Description',\n",
    "        'Number of Services',\n",
    "        'Number of Medicare Beneficiaries',\n",
    "        'Number of Distinct Medicare Beneficiary/Per Day Services',\n",
    "        'Average Medicare Allowed Amount']\n",
    "\n",
    "df_payments_2017 = pd.read_csv('../data/Medicare_Provider_Utilization_and_Payment_Data__Physician_and_Other_Supplier_PUF_CY2017.csv', \n",
    "                               usecols = cols)\n",
    "df_payments_2017['year'] = 2017\n",
    "df_payments_2017.columns = df_payments_2017.columns.str.replace(\" \", \"_\").str.replace(\"/\", \"_\").str.lower()\n",
    "df_payments_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_payments_2016 = pd.read_csv('../data/Medicare_Provider_Utilization_and_Payment_Data__Physician_and_Other_Supplier_PUF_CY2016.csv', \n",
    "                               usecols = cols)\n",
    "df_payments_2016['year'] = 2016\n",
    "df_payments_2016.columns = df_payments_2016.columns.str.replace(\" \", \"_\").str.replace(\"/\", \"_\").str.lower()\n",
    "df_payments_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_payments_2015 = pd.read_csv('../data/Medicare_Provider_Utilization_and_Payment_Data__Physician_and_Other_Supplier_PUF_CY2015.csv', \n",
    "                               usecols = cols)\n",
    "df_payments_2015['year'] = 2015\n",
    "df_payments_2015.columns = df_payments_2015.columns.str.replace(\" \", \"_\").str.replace(\"/\", \"_\").str.lower()\n",
    "df_payments_2015.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPDATE:  6/2/2020  To remove irrelevant row from 2015 file (all values are NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find item that needs to be dropped from 2015, has irrelevant text in last name field (like a footnote) and\n",
    "# no other data in any rows\n",
    "\n",
    "df_payments_2015[df_payments_2015.national_provider_identifier == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To drop the irrelevant row, index # 7205022\n",
    "\n",
    "df_payments_2015 = df_payments_2015.drop(labels = 7205022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure that the irrelevant row was dropped (CONFIRMED)\n",
    "\n",
    "df_payments_2015[df_payments_2015.national_provider_identifier == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pickle file for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_payments_2017.to_pickle('..\\data\\pickled_files\\payments_2017.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_payments_2016.to_pickle('..\\data\\pickled_files\\payments_2016.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_payments_2015.to_pickle('..\\data\\pickled_files\\payments_2015.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine three years into a single file using concat.  Create pickle file.\n",
    "- Resulting df will show 3 rows for each provider for each HCPCS code: one for each year (2015, 2016, 2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_payments_combined_draft = pd.concat([df_payments_2015, df_payments_2016, df_payments_2017], ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a pickle file for combined data\n",
    "\n",
    "df_payments_combined_draft.to_pickle('..\\data\\pickled_files\\payments_combined_draft.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work is contined in next notebook named \"step02_clean_combined_df\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
